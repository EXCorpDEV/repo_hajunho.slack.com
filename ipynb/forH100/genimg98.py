import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm

# ============================================================================
# ì„¤ì •
# ============================================================================
device = torch.device('cuda:0')
batch_size = 128
epochs = 30  # Fashion-MNISTëŠ” ì¡°ê¸ˆ ë” ë³µì¡í•´ì„œ ì—í­ ì¦ê°€
lr = 0.0002
latent_dim = 100
num_classes = 10
img_size = 28

# Fashion-MNIST í´ë˜ìŠ¤ ì´ë¦„
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

print(f"ğŸ–¥ï¸  ì‚¬ìš© GPU: {torch.cuda.get_device_name(0)}")
print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\n")

# ============================================================================
# ë°ì´í„° ë¡œë“œ
# ============================================================================
print("ğŸ“¦ Fashion-MNIST ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...")
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)

print(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(train_dataset)}ê°œ ì´ë¯¸ì§€")
print(f"ğŸ“‹ í´ë˜ìŠ¤: {', '.join(class_names)}\n")

# ============================================================================
# Generator ëª¨ë¸ (ë” ê¹Šê³  ê°•ë ¥í•˜ê²Œ)
# ============================================================================
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        
        self.label_emb = nn.Embedding(num_classes, num_classes)
        
        self.model = nn.Sequential(
            nn.Linear(latent_dim + num_classes, 256),
            nn.LeakyReLU(0.2),
            nn.BatchNorm1d(256),
            nn.Dropout(0.3),
            
            nn.Linear(256, 512),
            nn.LeakyReLU(0.2),
            nn.BatchNorm1d(512),
            nn.Dropout(0.3),
            
            nn.Linear(512, 1024),
            nn.LeakyReLU(0.2),
            nn.BatchNorm1d(1024),
            nn.Dropout(0.3),
            
            nn.Linear(1024, img_size * img_size),
            nn.Tanh()
        )
    
    def forward(self, noise, labels):
        label_input = self.label_emb(labels)
        gen_input = torch.cat([noise, label_input], dim=1)
        img = self.model(gen_input)
        img = img.view(img.size(0), 1, img_size, img_size)
        return img

# ============================================================================
# Discriminator ëª¨ë¸
# ============================================================================
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        
        self.label_emb = nn.Embedding(num_classes, num_classes)
        
        self.model = nn.Sequential(
            nn.Linear(img_size * img_size + num_classes, 512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.4),
            
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.4),
            
            nn.Linear(256, 128),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.4),
            
            nn.Linear(128, 1),
            nn.Sigmoid()
        )
    
    def forward(self, img, labels):
        img_flat = img.view(img.size(0), -1)
        label_input = self.label_emb(labels)
        d_input = torch.cat([img_flat, label_input], dim=1)
        validity = self.model(d_input)
        return validity

# ============================================================================
# ëª¨ë¸ ì´ˆê¸°í™”
# ============================================================================
generator = Generator().to(device)
discriminator = Discriminator().to(device)

optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

criterion = nn.BCELoss()

print("ğŸ¯ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
print(f"   Generator íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in generator.parameters()):,}")
print(f"   Discriminator íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in discriminator.parameters()):,}\n")

# ============================================================================
# í•™ìŠµ
# ============================================================================
print("ğŸš€ í•™ìŠµ ì‹œì‘! (Fashion-MNISTëŠ” ì¡°ê¸ˆ ë” ê±¸ë ¤ìš”)\n")

G_losses = []
D_losses = []

for epoch in range(epochs):
    g_loss_epoch = 0
    d_loss_epoch = 0
    
    pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}")
    
    for i, (imgs, labels) in enumerate(pbar):
        batch_size_current = imgs.size(0)
        
        real_imgs = imgs.to(device)
        labels = labels.to(device)
        
        # ì‹¤ì œ/ê°€ì§œ ë ˆì´ë¸” (Label smoothing ì ìš©)
        real_label = torch.ones(batch_size_current, 1, device=device) * 0.9
        fake_label = torch.zeros(batch_size_current, 1, device=device) + 0.1
        
        # ============================
        # Discriminator í•™ìŠµ
        # ============================
        optimizer_D.zero_grad()
        
        # ì‹¤ì œ ì´ë¯¸ì§€
        real_loss = criterion(discriminator(real_imgs, labels), real_label)
        
        # ê°€ì§œ ì´ë¯¸ì§€
        noise = torch.randn(batch_size_current, latent_dim, device=device)
        fake_imgs = generator(noise, labels)
        fake_loss = criterion(discriminator(fake_imgs.detach(), labels), fake_label)
        
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward()
        optimizer_D.step()
        
        # ============================
        # Generator í•™ìŠµ
        # ============================
        optimizer_G.zero_grad()
        
        noise = torch.randn(batch_size_current, latent_dim, device=device)
        gen_labels = torch.randint(0, num_classes, (batch_size_current,), device=device)
        fake_imgs = generator(noise, gen_labels)
        
        g_loss = criterion(discriminator(fake_imgs, gen_labels), torch.ones(batch_size_current, 1, device=device))
        g_loss.backward()
        optimizer_G.step()
        
        # ì†ì‹¤ ê¸°ë¡
        g_loss_epoch += g_loss.item()
        d_loss_epoch += d_loss.item()
        
        pbar.set_postfix({
            'D_loss': f'{d_loss.item():.4f}',
            'G_loss': f'{g_loss.item():.4f}'
        })
    
    # ì—í­ í‰ê·  ì†ì‹¤
    G_losses.append(g_loss_epoch / len(train_loader))
    D_losses.append(d_loss_epoch / len(train_loader))
    
    print(f"Epoch [{epoch+1}/{epochs}] - D_loss: {D_losses[-1]:.4f}, G_loss: {G_losses[-1]:.4f}")
    
    # ì¤‘ê°„ ê²°ê³¼ ì‹œê°í™” (5 ì—í­ë§ˆë‹¤)
    if (epoch + 1) % 5 == 0:
        generator.eval()
        with torch.no_grad():
            fig, axes = plt.subplots(2, 5, figsize=(15, 6))
            fig.suptitle(f'Epoch {epoch+1} - ìƒì„± ê²°ê³¼', fontsize=14, fontweight='bold')
            
            for cls in range(10):
                noise = torch.randn(1, latent_dim, device=device)
                label = torch.tensor([cls], device=device)
                generated_img = generator(noise, label)
                img = generated_img.cpu().squeeze().numpy()
                img = (img + 1) / 2
                
                row = cls // 5
                col = cls % 5
                axes[row, col].imshow(img, cmap='gray')
                axes[row, col].set_title(class_names[cls], fontsize=10)
                axes[row, col].axis('off')
            
            plt.tight_layout()
            plt.show()
        generator.train()

print("\nâœ… í•™ìŠµ ì™„ë£Œ!\n")

# ============================================================================
# ìµœì¢… ê²°ê³¼ ì‹œê°í™”
# ============================================================================
print("ğŸ¨ ìµœì¢… ì´ë¯¸ì§€ ìƒì„± ì¤‘...\n")

generator.eval()

# ê° í´ë˜ìŠ¤ë³„ ìƒì„±
fig, axes = plt.subplots(2, 5, figsize=(15, 6))
fig.suptitle('Fashion-MNIST GAN - ìƒì„±ëœ íŒ¨ì…˜ ì•„ì´í…œë“¤', fontsize=16, fontweight='bold')

with torch.no_grad():
    for cls in range(10):
        noise = torch.randn(1, latent_dim, device=device)
        label = torch.tensor([cls], device=device)
        
        generated_img = generator(noise, label)
        img = generated_img.cpu().squeeze().numpy()
        img = (img + 1) / 2
        
        row = cls // 5
        col = cls % 5
        axes[row, col].imshow(img, cmap='gray')
        axes[row, col].set_title(f'{class_names[cls]}', fontsize=11, fontweight='bold')
        axes[row, col].axis('off')

plt.tight_layout()
plt.savefig('fashion_mnist_gan_results.png', dpi=150, bbox_inches='tight')
plt.show()

print("ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥: fashion_mnist_gan_results.png")

# ì†ì‹¤ ê·¸ë˜í”„
fig, ax = plt.subplots(1, 1, figsize=(10, 5))
ax.plot(G_losses, label='Generator Loss', linewidth=2)
ax.plot(D_losses, label='Discriminator Loss', linewidth=2)
ax.set_xlabel('Epoch', fontsize=12)
ax.set_ylabel('Loss', fontsize=12)
ax.set_title('Fashion-MNIST GAN Training Loss', fontsize=14, fontweight='bold')
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('fashion_mnist_gan_loss.png', dpi=150, bbox_inches='tight')
plt.show()

print("ğŸ’¾ ì†ì‹¤ ê·¸ë˜í”„ ì €ì¥: fashion_mnist_gan_loss.png")

# ============================================================================
# í´ë˜ìŠ¤ë³„ ë‹¤ì–‘í•œ ìƒ˜í”Œ ìƒì„±
# ============================================================================
print("\nğŸ¨ í´ë˜ìŠ¤ë³„ ë‹¤ì–‘í•œ ìƒ˜í”Œ ìƒì„± ì¤‘...\n")

fig, axes = plt.subplots(10, 8, figsize=(16, 20))
fig.suptitle('Fashion-MNIST GAN - í´ë˜ìŠ¤ë³„ 8ê°œ ìƒ˜í”Œ', fontsize=16, fontweight='bold')

with torch.no_grad():
    for cls in range(10):
        for sample in range(8):
            noise = torch.randn(1, latent_dim, device=device)
            label = torch.tensor([cls], device=device)
            
            generated_img = generator(noise, label)
            img = generated_img.cpu().squeeze().numpy()
            img = (img + 1) / 2
            
            axes[cls, sample].imshow(img, cmap='gray')
            if sample == 0:
                axes[cls, sample].set_ylabel(class_names[cls], fontsize=10, fontweight='bold')
            axes[cls, sample].axis('off')

plt.tight_layout()
plt.savefig('fashion_mnist_gan_samples.png', dpi=150, bbox_inches='tight')
plt.show()

print("ğŸ’¾ ìƒ˜í”Œ ì´ë¯¸ì§€ ì €ì¥: fashion_mnist_gan_samples.png")

# ============================================================================
# ì‹¤ì œ vs ìƒì„± ë¹„êµ
# ============================================================================
print("\nğŸ” ì‹¤ì œ ì´ë¯¸ì§€ vs ìƒì„± ì´ë¯¸ì§€ ë¹„êµ...\n")

# ì‹¤ì œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
real_samples = []
real_labels = []
for imgs, labels in train_loader:
    real_samples.append(imgs)
    real_labels.append(labels)
    if len(real_samples) >= 1:
        break

real_samples = real_samples[0][:10].to(device)
real_labels = real_labels[0][:10].to(device)

fig, axes = plt.subplots(2, 10, figsize=(20, 4))
fig.suptitle('ì‹¤ì œ ì´ë¯¸ì§€ (ìœ„) vs ìƒì„± ì´ë¯¸ì§€ (ì•„ë˜)', fontsize=14, fontweight='bold')

with torch.no_grad():
    for i in range(10):
        # ì‹¤ì œ ì´ë¯¸ì§€
        real_img = real_samples[i].cpu().squeeze().numpy()
        real_img = (real_img + 1) / 2
        axes[0, i].imshow(real_img, cmap='gray')
        axes[0, i].set_title(f'Real: {class_names[real_labels[i]]}', fontsize=8)
        axes[0, i].axis('off')
        
        # ìƒì„± ì´ë¯¸ì§€ (ê°™ì€ í´ë˜ìŠ¤)
        noise = torch.randn(1, latent_dim, device=device)
        label = real_labels[i].unsqueeze(0)
        generated_img = generator(noise, label)
        gen_img = generated_img.cpu().squeeze().numpy()
        gen_img = (gen_img + 1) / 2
        axes[1, i].imshow(gen_img, cmap='gray')
        axes[1, i].set_title(f'Gen: {class_names[real_labels[i]]}', fontsize=8)
        axes[1, i].axis('off')

plt.tight_layout()
plt.savefig('fashion_mnist_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

print("ğŸ’¾ ë¹„êµ ì´ë¯¸ì§€ ì €ì¥: fashion_mnist_comparison.png")
print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
