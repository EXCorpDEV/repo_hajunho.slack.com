import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm

# ============================================================================
# ì„¤ì •
# ============================================================================
device = torch.device('cuda:0')
batch_size = 128
epochs = 50  # ì»¬ëŸ¬ ì´ë¯¸ì§€ëŠ” ë” ë³µì¡
lr = 0.0002
latent_dim = 100
num_classes = 10
img_size = 32
channels = 3

# CIFAR-10 í´ë˜ìŠ¤ ì´ë¦„
class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',
               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']

print(f"ğŸ–¥ï¸  ì‚¬ìš© GPU: {torch.cuda.get_device_name(0)}")
print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\n")

# ============================================================================
# ë°ì´í„° ë¡œë“œ
# ============================================================================
print("ğŸ“¦ CIFAR-10 ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...")
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])

train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)

print(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(train_dataset)}ê°œ ì»¬ëŸ¬ ì´ë¯¸ì§€")
print(f"ğŸ“‹ í´ë˜ìŠ¤: {', '.join(class_names)}\n")

# ============================================================================
# Generator ëª¨ë¸ (CNN ê¸°ë°˜ - DCGAN ìŠ¤íƒ€ì¼)
# ============================================================================
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        
        self.label_emb = nn.Embedding(num_classes, num_classes)
        
        # Initial projection
        self.init_size = img_size // 4  # 8
        self.l1 = nn.Sequential(
            nn.Linear(latent_dim + num_classes, 128 * self.init_size * self.init_size)
        )
        
        # Convolutional layers
        self.conv_blocks = nn.Sequential(
            nn.BatchNorm2d(128),
            
            nn.Upsample(scale_factor=2),  # 8 -> 16
            nn.Conv2d(128, 128, 3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            
            nn.Upsample(scale_factor=2),  # 16 -> 32
            nn.Conv2d(128, 64, 3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2, inplace=True),
            
            nn.Conv2d(64, channels, 3, stride=1, padding=1),
            nn.Tanh()
        )
    
    def forward(self, noise, labels):
        label_input = self.label_emb(labels)
        gen_input = torch.cat([noise, label_input], dim=1)
        
        out = self.l1(gen_input)
        out = out.view(out.shape[0], 128, self.init_size, self.init_size)
        img = self.conv_blocks(out)
        
        return img

# ============================================================================
# Discriminator ëª¨ë¸ (CNN ê¸°ë°˜)
# ============================================================================
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        
        self.label_emb = nn.Embedding(num_classes, num_classes)
        
        def discriminator_block(in_filters, out_filters, bn=True):
            block = [
                nn.Conv2d(in_filters, out_filters, 3, 2, 1),
                nn.LeakyReLU(0.2, inplace=True),
                nn.Dropout2d(0.25)
            ]
            if bn:
                block.append(nn.BatchNorm2d(out_filters))
            return block
        
        self.conv_blocks = nn.Sequential(
            *discriminator_block(channels, 16, bn=False),  # 32 -> 16
            *discriminator_block(16, 32),  # 16 -> 8
            *discriminator_block(32, 64),  # 8 -> 4
            *discriminator_block(64, 128),  # 4 -> 2
        )
        
        # Output size after conv blocks
        ds_size = img_size // 2 ** 4  # 2
        
        self.adv_layer = nn.Sequential(
            nn.Linear(128 * ds_size * ds_size + num_classes, 1),
            nn.Sigmoid()
        )
    
    def forward(self, img, labels):
        out = self.conv_blocks(img)
        out = out.view(out.shape[0], -1)
        label_input = self.label_emb(labels)
        d_input = torch.cat([out, label_input], dim=1)
        validity = self.adv_layer(d_input)
        
        return validity

# ============================================================================
# ëª¨ë¸ ì´ˆê¸°í™”
# ============================================================================
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

generator.apply(weights_init)
discriminator.apply(weights_init)

optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

criterion = nn.BCELoss()

print("ğŸ¯ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
print(f"   Generator íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in generator.parameters()):,}")
print(f"   Discriminator íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in discriminator.parameters()):,}\n")

# ============================================================================
# í•™ìŠµ
# ============================================================================
print("ğŸš€ í•™ìŠµ ì‹œì‘! (ì»¬ëŸ¬ ì´ë¯¸ì§€ë¼ ì‹œê°„ì´ ì¢€ ê±¸ë ¤ìš”~)\n")

G_losses = []
D_losses = []

for epoch in range(epochs):
    g_loss_epoch = 0
    d_loss_epoch = 0
    
    pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}")
    
    for i, (imgs, labels) in enumerate(pbar):
        batch_size_current = imgs.size(0)
        
        real_imgs = imgs.to(device)
        labels = labels.to(device)
        
        # ì‹¤ì œ/ê°€ì§œ ë ˆì´ë¸” (Label smoothing)
        real_label = torch.ones(batch_size_current, 1, device=device) * 0.9
        fake_label = torch.zeros(batch_size_current, 1, device=device) + 0.1
        
        # ============================
        # Discriminator í•™ìŠµ
        # ============================
        optimizer_D.zero_grad()
        
        # ì‹¤ì œ ì´ë¯¸ì§€
        real_loss = criterion(discriminator(real_imgs, labels), real_label)
        
        # ê°€ì§œ ì´ë¯¸ì§€
        noise = torch.randn(batch_size_current, latent_dim, device=device)
        fake_imgs = generator(noise, labels)
        fake_loss = criterion(discriminator(fake_imgs.detach(), labels), fake_label)
        
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward()
        optimizer_D.step()
        
        # ============================
        # Generator í•™ìŠµ
        # ============================
        optimizer_G.zero_grad()
        
        noise = torch.randn(batch_size_current, latent_dim, device=device)
        gen_labels = torch.randint(0, num_classes, (batch_size_current,), device=device)
        fake_imgs = generator(noise, gen_labels)
        
        g_loss = criterion(discriminator(fake_imgs, gen_labels), torch.ones(batch_size_current, 1, device=device))
        g_loss.backward()
        optimizer_G.step()
        
        # ì†ì‹¤ ê¸°ë¡
        g_loss_epoch += g_loss.item()
        d_loss_epoch += d_loss.item()
        
        pbar.set_postfix({
            'D_loss': f'{d_loss.item():.4f}',
            'G_loss': f'{g_loss.item():.4f}'
        })
    
    # ì—í­ í‰ê·  ì†ì‹¤
    G_losses.append(g_loss_epoch / len(train_loader))
    D_losses.append(d_loss_epoch / len(train_loader))
    
    print(f"Epoch [{epoch+1}/{epochs}] - D_loss: {D_losses[-1]:.4f}, G_loss: {G_losses[-1]:.4f}")
    
    # ì¤‘ê°„ ê²°ê³¼ ì‹œê°í™” (10 ì—í­ë§ˆë‹¤)
    if (epoch + 1) % 10 == 0:
        generator.eval()
        with torch.no_grad():
            fig, axes = plt.subplots(2, 5, figsize=(15, 6))
            fig.suptitle(f'Epoch {epoch+1} - CIFAR-10 ìƒì„± ê²°ê³¼', fontsize=14, fontweight='bold')
            
            for cls in range(10):
                noise = torch.randn(1, latent_dim, device=device)
                label = torch.tensor([cls], device=device)
                generated_img = generator(noise, label)
                img = generated_img.cpu().squeeze().permute(1, 2, 0).numpy()
                img = (img + 1) / 2
                img = np.clip(img, 0, 1)
                
                row = cls // 5
                col = cls % 5
                axes[row, col].imshow(img)
                axes[row, col].set_title(class_names[cls], fontsize=10)
                axes[row, col].axis('off')
            
            plt.tight_layout()
            plt.show()
        generator.train()

print("\nâœ… í•™ìŠµ ì™„ë£Œ!\n")

# ============================================================================
# ìµœì¢… ê²°ê³¼ ì‹œê°í™”
# ============================================================================
print("ğŸ¨ ìµœì¢… ì»¬ëŸ¬ ì´ë¯¸ì§€ ìƒì„± ì¤‘...\n")

generator.eval()

# ê° í´ë˜ìŠ¤ë³„ ìƒì„±
fig, axes = plt.subplots(2, 5, figsize=(15, 6))
fig.suptitle('CIFAR-10 GAN - ìƒì„±ëœ ì»¬ëŸ¬ ì´ë¯¸ì§€ë“¤', fontsize=16, fontweight='bold')

with torch.no_grad():
    for cls in range(10):
        noise = torch.randn(1, latent_dim, device=device)
        label = torch.tensor([cls], device=device)
        
        generated_img = generator(noise, label)
        img = generated_img.cpu().squeeze().permute(1, 2, 0).numpy()
        img = (img + 1) / 2
        img = np.clip(img, 0, 1)
        
        row = cls // 5
        col = cls % 5
        axes[row, col].imshow(img)
        axes[row, col].set_title(f'{class_names[cls]}', fontsize=11, fontweight='bold')
        axes[row, col].axis('off')

plt.tight_layout()
plt.savefig('cifar10_gan_results.png', dpi=150, bbox_inches='tight')
plt.show()

print("ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥: cifar10_gan_results.png")

# ì†ì‹¤ ê·¸ë˜í”„
fig, ax = plt.subplots(1, 1, figsize=(12, 5))
ax.plot(G_losses, label='Generator Loss', linewidth=2, alpha=0.8)
ax.plot(D_losses, label='Discriminator Loss', linewidth=2, alpha=0.8)
ax.set_xlabel('Epoch', fontsize=12)
ax.set_ylabel('Loss', fontsize=12)
ax.set_title('CIFAR-10 GAN Training Loss', fontsize=14, fontweight='bold')
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('cifar10_gan_loss.png', dpi=150, bbox_inches='tight')
plt.show()

print("ğŸ’¾ ì†ì‹¤ ê·¸ë˜í”„ ì €ì¥: cifar10_gan_loss.png")

# ============================================================================
# í´ë˜ìŠ¤ë³„ ë‹¤ì–‘í•œ ìƒ˜í”Œ ìƒì„± (5ê°œì”©)
# ============================================================================
print("\nğŸ¨ í´ë˜ìŠ¤ë³„ ë‹¤ì–‘í•œ ìƒ˜í”Œ ìƒì„± ì¤‘...\n")

fig, axes = plt.subplots(10, 5, figsize=(12, 24))
fig.suptitle('CIFAR-10 GAN - í´ë˜ìŠ¤ë³„ 5ê°œ ìƒ˜í”Œ', fontsize=16, fontweight='bold')

with torch.no_grad():
    for cls in range(10):
        for sample in range(5):
            noise = torch.randn(1, latent_dim, device=device)
            label = torch.tensor([cls], device=device)
            
            generated_img = generator(noise, label)
            img = generated_img.cpu().squeeze().permute(1, 2, 0).numpy()
            img = (img + 1) / 2
            img = np.clip(img, 0, 1)
            
            axes[cls, sample].imshow(img)
            if sample == 0:
                axes[cls, sample].set_ylabel(class_names[cls], fontsize=11, fontweight='bold')
            axes[cls, sample].axis('off')

plt.tight_layout()
plt.savefig('cifar10_gan_samples.png', dpi=150, bbox_inches='tight')
plt.show()

print("ğŸ’¾ ìƒ˜í”Œ ì´ë¯¸ì§€ ì €ì¥: cifar10_gan_samples.png")

# ============================================================================
# ì‹¤ì œ vs ìƒì„± ë¹„êµ
# ============================================================================
print("\nğŸ” ì‹¤ì œ ì´ë¯¸ì§€ vs ìƒì„± ì´ë¯¸ì§€ ë¹„êµ...\n")

# ì‹¤ì œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
real_samples = []
real_labels = []
for imgs, labels in train_loader:
    real_samples.append(imgs)
    real_labels.append(labels)
    if len(real_samples) >= 1:
        break

real_samples = real_samples[0][:10].to(device)
real_labels = real_labels[0][:10].to(device)

fig, axes = plt.subplots(2, 10, figsize=(20, 4))
fig.suptitle('ì‹¤ì œ ì´ë¯¸ì§€ (ìœ„) vs ìƒì„± ì´ë¯¸ì§€ (ì•„ë˜)', fontsize=14, fontweight='bold')

with torch.no_grad():
    for i in range(10):
        # ì‹¤ì œ ì´ë¯¸ì§€
        real_img = real_samples[i].cpu().permute(1, 2, 0).numpy()
        real_img = (real_img + 1) / 2
        real_img = np.clip(real_img, 0, 1)
        axes[0, i].imshow(real_img)
        axes[0, i].set_title(f'{class_names[real_labels[i]]}', fontsize=8)
        axes[0, i].axis('off')
        
        # ìƒì„± ì´ë¯¸ì§€
        noise = torch.randn(1, latent_dim, device=device)
        label = real_labels[i].unsqueeze(0)
        generated_img = generator(noise, label)
        gen_img = generated_img.cpu().squeeze().permute(1, 2, 0).numpy()
        gen_img = (gen_img + 1) / 2
        gen_img = np.clip(gen_img, 0, 1)
        axes[1, i].imshow(gen_img)
        axes[1, i].set_title(f'{class_names[real_labels[i]]}', fontsize=8)
        axes[1, i].axis('off')

plt.tight_layout()
plt.savefig('cifar10_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

print("ğŸ’¾ ë¹„êµ ì´ë¯¸ì§€ ì €ì¥: cifar10_comparison.png")

# ============================================================================
# ëŒ€ëŸ‰ ìƒ˜í”Œ ê·¸ë¦¬ë“œ
# ============================================================================
print("\nğŸ¨ 100ê°œ ëœë¤ ìƒ˜í”Œ ìƒì„± ì¤‘...\n")

fig, axes = plt.subplots(10, 10, figsize=(20, 20))
fig.suptitle('CIFAR-10 GAN - 100ê°œ ëœë¤ ìƒ˜í”Œ', fontsize=18, fontweight='bold')

with torch.no_grad():
    for i in range(100):
        noise = torch.randn(1, latent_dim, device=device)
        random_label = torch.randint(0, 10, (1,), device=device)
        
        generated_img = generator(noise, random_label)
        img = generated_img.cpu().squeeze().permute(1, 2, 0).numpy()
        img = (img + 1) / 2
        img = np.clip(img, 0, 1)
        
        row = i // 10
        col = i % 10
        axes[row, col].imshow(img)
        axes[row, col].axis('off')

plt.tight_layout()
plt.savefig('cifar10_gan_grid.png', dpi=150, bbox_inches='tight')
plt.show()

print("ğŸ’¾ ê·¸ë¦¬ë“œ ì´ë¯¸ì§€ ì €ì¥: cifar10_gan_grid.png")
print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
