import os
import warnings
import logging

# TensorFlow ë¡œê·¸ ë ˆë²¨ ì„¤ì • (ì—ëŸ¬ ë©”ì‹œì§€ ì¤„ì´ê¸°)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
logging.getLogger('tensorflow').setLevel(logging.ERROR)
warnings.filterwarnings('ignore')

import tensorflow as tf
import shutil
from pathlib import Path
import gc

# í•™ìŠµí•  í´ë˜ìŠ¤ ëª©ë¡
TARGET_CLASSES = list(set([
    "ë‹­ê°ˆë¹„", "í›ˆì œì˜¤ë¦¬", "ì½©ë‚˜ë¬¼", "ì°¹ìŒ€ë–¡", "ìŒ€êµ­ìˆ˜", "ë¹„ë¹”ë°¥", "ì—°ì–´ì´ˆë°¥", "ì¥ì–´ì´ˆë°¥",
    "ìˆœëŒ€ë³¶ìŒ", "ì°¸ì¹˜ìƒŒë“œìœ„ì¹˜", "ê¹€ì¹˜ì°Œê°œ", "ë¶€ëŒ€ì°Œê°œ", "ìˆœëŒ€", "ì´ˆì½œë¦¿", "ìˆœì‚´ì¹˜í‚¨",
    "ì—ê·¸íƒ€ë¥´íŠ¸", "ì¹˜í‚¨ë„ˆê²Ÿ", "ê³ ë“±ì–´êµ¬ì´", "ë“±ì‹¬ìŠ¤í…Œì´í¬", "ì‚¼ê²¹ì‚´êµ¬ì´", "ì¡°ë¯¸ê¹€",
    "ë¯¸ì—­êµ­", "ì‚¼ê³„íƒ•", "ì–´ë¬µêµ­", "ë°°ì¶”ê¹€ì¹˜", "ì˜¤ì´ê¹€ì¹˜", "ìˆ™ì£¼ë‚˜ë¬¼", "êµ°ë§Œë‘", "ë–¡êµ­",
    "ë¼ë©´", "ë§Œë‘", "ë¹„ë¹”ëƒ‰ë©´", "ì§œì¥ë©´", "ì§¬ë½•", "ê¹€ë°¥", "ë¹„ë¹”ë°¥", "ì•Œë°¥", "ì˜¤ë¯€ë¼ì´ìŠ¤",
    "ìœ¡íšŒë¹„ë¹”ë°¥", "ë–¡ë³¶ì´", "ì¡ì±„", "ë‹­ê°€ìŠ´ì‚´ìƒëŸ¬ë“œ", "ìœ¡íšŒ", "ë§ˆëŠ˜ì¥ì•„ì°Œ", "ë–¡ê°ˆë¹„",
    "ìŠ¤í¬ë¨ë¸”ë“œì—ê·¸", "ì±„ì†Œì£½", "ëœì¥ì°Œê°œ", "ë¶€ëŒ€ì°Œê°œ", "ìˆœë‘ë¶€ì°Œê°œ", "ë‹¬ê±€ì°œ", "ë‹­ì°œ",
    "ë¼ì§€ê°ˆë¹„ì°œ", "ìˆœëŒ€", "ì•„ê·€ì°œ", "ì¡±ë°œ", "ê°ìíŠ€ê¹€", "ì˜¤ì§•ì–´íŠ€ê¹€", "ì¹˜í‚¨ë„ˆê²Ÿ",
    "í›„ë¼ì´ë“œì¹˜í‚¨", "ê¹Œë¥´ë³´ë‚˜ë¼", "ì¸„ëŸ¬ìŠ¤", "ì´ˆì½”ì•„ì´ìŠ¤í¬ë¦¼"
]))

def filter_classes(source_dir, target_dir):
    """ì§€ì •ëœ í´ë˜ìŠ¤ë§Œ í•„í„°ë§"""
    source_path = Path(source_dir)
    target_path = Path(target_dir)
    
    # íƒ€ê²Ÿ ë””ë ‰í† ë¦¬ ìƒì„±
    target_path.mkdir(exist_ok=True)
    
    copied_classes = []
    skipped_classes = []
    
    print(f"\n=== í´ë˜ìŠ¤ í•„í„°ë§ ì‹œì‘ ===")
    print(f"ì›ë³¸ ë””ë ‰í† ë¦¬: {source_dir}")
    print(f"í•„í„°ë§ëœ ë””ë ‰í† ë¦¬: {target_dir}")
    print(f"íƒ€ê²Ÿ í´ë˜ìŠ¤ ìˆ˜: {len(TARGET_CLASSES)}")
    
    # ì›ë³¸ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  í´ë” í™•ì¸
    for folder in source_path.iterdir():
        if folder.is_dir():
            folder_name = folder.name
            
            if folder_name in TARGET_CLASSES:
                # íƒ€ê²Ÿ í´ë˜ìŠ¤ì— í¬í•¨ë˜ë©´ ë³µì‚¬
                target_class_dir = target_path / folder_name
                
                if target_class_dir.exists():
                    shutil.rmtree(target_class_dir)
                
                shutil.copytree(folder, target_class_dir)
                
                # ì´ë¯¸ì§€ ê°œìˆ˜ ì„¸ê¸°
                image_count = len([f for f in target_class_dir.iterdir() 
                                 if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']])
                
                copied_classes.append((folder_name, image_count))
                print(f"âœ… {folder_name}: {image_count}ê°œ ì´ë¯¸ì§€")
                
            else:
                skipped_classes.append(folder_name)
    
    print(f"\në³µì‚¬ëœ í´ë˜ìŠ¤: {len(copied_classes)}ê°œ")
    print(f"ê±´ë„ˆë›´ í´ë˜ìŠ¤: {len(skipped_classes)}ê°œ")
    
    if skipped_classes:
        print(f"ê±´ë„ˆë›´ í´ë˜ìŠ¤ë“¤: {', '.join(skipped_classes[:10])}{'...' if len(skipped_classes) > 10 else ''}")
    
    # ëˆ„ë½ëœ íƒ€ê²Ÿ í´ë˜ìŠ¤ í™•ì¸
    copied_class_names = [name for name, _ in copied_classes]
    missing_classes = [cls for cls in TARGET_CLASSES if cls not in copied_class_names]
    
    if missing_classes:
        print(f"\nâš ï¸ ëˆ„ë½ëœ íƒ€ê²Ÿ í´ë˜ìŠ¤: {len(missing_classes)}ê°œ")
        print(f"ëˆ„ë½ëœ í´ë˜ìŠ¤ë“¤: {', '.join(missing_classes[:10])}{'...' if len(missing_classes) > 10 else ''}")
    
    return target_dir, len(copied_classes)

def main():
    print("=== ê·¹ë‹¨ì  ë©”ëª¨ë¦¬ ì ˆì•½ í›ˆë ¨ ===")
    print(f"íƒ€ê²Ÿ í´ë˜ìŠ¤ ìˆ˜: {len(TARGET_CLASSES)}")
    
    # ê·¹ë„ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½í•˜ëŠ” ì„¤ì •
    original_data_dir = './'
    filtered_data_dir = './filtered_classes'
    batch_size = 8  # 32 â†’ 8ë¡œ ëŒ€í­ ê°ì†Œ
    img_height = 128  # 224 â†’ 128ë¡œ ê°ì†Œ
    img_width = 128
    epochs = 5  # 10 â†’ 5ë¡œ ê°ì†Œ
    model_save_path = 'ultra_small_food_classifier.keras'
    tflite_save_path = 'ultra_small_food_classifier.tflite'
    class_names_file = 'ultra_small_class_names.txt'
    
    print(f"\nâš ï¸ ê·¹ë‹¨ì  ë©”ëª¨ë¦¬ ì ˆì•½ ì„¤ì •:")
    print(f"- ë°°ì¹˜ ì‚¬ì´ì¦ˆ: {batch_size} (ì›ë³¸ 32ì—ì„œ ê°ì†Œ)")
    print(f"- ì´ë¯¸ì§€ í¬ê¸°: {img_height}x{img_width} (ì›ë³¸ 224x224ì—ì„œ ê°ì†Œ)")
    print(f"- ì—í­ ìˆ˜: {epochs} (ì›ë³¸ 10ì—ì„œ ê°ì†Œ)")
    
    # í´ë˜ìŠ¤ í•„í„°ë§
    filtered_dir, actual_class_count = filter_classes(original_data_dir, filtered_data_dir)
    
    if actual_class_count == 0:
        print("âŒ í•„í„°ë§ëœ í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nì‹¤ì œ ì‚¬ìš©í•  í´ë˜ìŠ¤ ìˆ˜: {actual_class_count}")
    
    # ë°ì´í„°ì…‹ ìƒì„± (ì‘ì€ í¬ê¸°ë¡œ)
    print("\nì‘ì€ í¬ê¸° ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
    
    train_ds = tf.keras.preprocessing.image_dataset_from_directory(
        filtered_dir,
        labels='inferred',
        label_mode='int',
        image_size=(img_height, img_width),  # ì‘ì€ í¬ê¸°
        batch_size=batch_size  # ì‘ì€ ë°°ì¹˜
    )
    
    # í´ë˜ìŠ¤ ì´ë¦„ í™•ì¸
    class_names = train_ds.class_names
    print(f"\nì‹¤ì œ ë¡œë“œëœ í´ë˜ìŠ¤ ìˆ˜: {len(class_names)}")
    
    # í´ë˜ìŠ¤ ì´ë¦„ ì €ì¥
    with open(class_names_file, 'w', encoding='utf-8') as f:
        for name in class_names:
            f.write(f"{name}\n")
    print(f"í´ë˜ìŠ¤ ëª©ë¡ ì €ì¥: {class_names_file}")
    
    # ê·¹ë„ë¡œ ì‘ì€ ëª¨ë¸ ìƒì„±
    print("\nê·¹ë„ë¡œ ì‘ì€ MobileNetV2 ëª¨ë¸ ìƒì„± ì¤‘...")
    
    base_model = tf.keras.applications.MobileNetV2(
        input_shape=(img_height, img_width, 3),
        include_top=False,
        weights='imagenet',
        alpha=0.35  # ëª¨ë¸ í¬ê¸°ë¥¼ 35%ë¡œ ì¶•ì†Œ
    )
    base_model.trainable = False
    
    inputs = tf.keras.Input(shape=(img_height, img_width, 3))
    x = base_model(inputs, training=False)
    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    # Dropout ì¶”ê°€ë¡œ ì˜¤ë²„í”¼íŒ… ë°©ì§€
    x = tf.keras.layers.Dropout(0.2)(x)
    outputs = tf.keras.layers.Dense(len(class_names), activation='softmax')(x)
    
    model = tf.keras.Model(inputs, outputs)
    
    # ëª¨ë¸ ì»´íŒŒì¼
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {model.count_params():,}")
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    gc.collect()
    
    # ì•ˆì „í•œ ì²« ë°°ì¹˜ í…ŒìŠ¤íŠ¸ (ë” ì‘ì€ ë°°ì¹˜ë¡œ)
    print("\nì•ˆì „í•œ ì²« ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì¤‘...")
    try:
        for batch in train_ds.take(1):
            print(f"ë°°ì¹˜ ëª¨ì–‘: {batch[0].shape}")
            
            # ë” ì‘ì€ ì„œë¸Œë°°ì¹˜ë¡œ í…ŒìŠ¤íŠ¸
            mini_batch = batch[0][:4]  # 8ê°œ ì¤‘ì—ì„œ 4ê°œë§Œ
            test_pred = model(mini_batch)
            print(f"ì˜ˆì¸¡ ëª¨ì–‘: {test_pred.shape}")
            print("âœ… ì²« ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            del mini_batch, test_pred
            gc.collect()
            break
            
    except Exception as e:
        print(f"âŒ ì²« ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        print("ë©”ëª¨ë¦¬ê°€ ì—¬ì „íˆ ë¶€ì¡±í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # í•™ìŠµ (ì¡°ê¸° ì¢…ë£Œ ì½œë°± ì¶”ê°€)
    print("\nì•ˆì „í•œ í•™ìŠµ ì‹œì‘...")
    
    # ë©”ëª¨ë¦¬ ë¶€ì¡±ì„ ëŒ€ë¹„í•œ ì½œë°±
    callbacks = [
        tf.keras.callbacks.EarlyStopping(
            monitor='loss',
            patience=2,
            restore_best_weights=True
        )
    ]
    
    try:
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        
        history = model.fit(
            train_ds, 
            epochs=epochs,
            callbacks=callbacks,
            verbose=1
        )
        
        # ëª¨ë¸ ì €ì¥
        print(f"\nëª¨ë¸ ì €ì¥ ì¤‘: {model_save_path}")
        model.save(model_save_path)
        
        # ëª¨ë¸ í¬ê¸° í™•ì¸
        size_mb = os.path.getsize(model_save_path) / (1024*1024)
        print(f"ëª¨ë¸ í¬ê¸°: {size_mb:.2f} MB")
        
        # TFLite ë³€í™˜
        print(f"\nTFLite ë³€í™˜ ì¤‘: {tflite_save_path}")
        converter = tf.lite.TFLiteConverter.from_saved_model(model_save_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        tflite_model = converter.convert()
        
        with open(tflite_save_path, 'wb') as f:
            f.write(tflite_model)
        
        tflite_size_mb = len(tflite_model) / (1024*1024)
        print(f"âœ… TFLite ë³€í™˜ ì„±ê³µ: {tflite_size_mb:.2f} MB")
        
        print(f"\nğŸ‰ ê·¹ë‹¨ì  ë©”ëª¨ë¦¬ ì ˆì•½ í›ˆë ¨ ì™„ë£Œ!")
        print(f"- í´ë˜ìŠ¤ ìˆ˜: {len(class_names)}")
        print(f"- ëª¨ë¸ íŒŒë¼ë¯¸í„°: {model.count_params():,}")
        print(f"- ëª¨ë¸ íŒŒì¼: {model_save_path}")
        print(f"- TFLite íŒŒì¼: {tflite_save_path}")
        print(f"- í´ë˜ìŠ¤ ëª©ë¡: {class_names_file}")
        
        print(f"\nğŸ’¡ ì„±ê³µí•˜ë©´ ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì ì§„ì ìœ¼ë¡œ ì„¤ì •ì„ ëŠ˜ë ¤ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        print(f"   1. ë°°ì¹˜ ì‚¬ì´ì¦ˆ: 8 â†’ 16 â†’ 32")
        print(f"   2. ì´ë¯¸ì§€ í¬ê¸°: 128 â†’ 160 â†’ 224")
        print(f"   3. ì—í­ ìˆ˜: 5 â†’ 10")
        
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
        print("ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ê°€ ì‹¬ê°í•˜ê²Œ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        print("ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•˜ê±°ë‚˜ ë” ë§ì€ ë©”ëª¨ë¦¬ê°€ ìˆëŠ” ì‹œìŠ¤í…œì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
